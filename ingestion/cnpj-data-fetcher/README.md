# cnpj-data-fetcher

Este √© um [Cloud Run Job](https://cloud.google.com/run/docs/create-jobs), constru√≠do em [NodeJS](https://nodejs.org). O job √© respons√°vel por baixar os [arquivos ZIP da Receita Federal](https://dados.gov.br/dados/conjuntos-dados/cadastro-nacional-da-pessoa-juridica---cnpj), realizar a extra√ß√£o de seus conte√∫dos e armazen√°-los no [Cloud Storage](https://cloud.google.com/storage).

## üèó Estrutura

```
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ env.js         # Vari√°veis de ambiente
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ controller/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ fetcher.js     # Orquestra√ß√£o do scraping, download, extra√ß√£o e upload para o GCP
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ service/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ download.js    # Download do arquivo ZIP da Receita
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ extract.js     # Extra√ß√£o do arquivo CSV oriundo do ZIP
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraping.js    # Scraping da p√°gina da Receita
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ storage.js     # Manipula√ß√£o de arquivos no GCS
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ util/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger.js      # Logs estruturados
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ alert.js       # Envio de alertas para o Slack
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ helper.js      # Fun√ß√µes auxiliares
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ main.js            # Ponto de entrada do processo
‚îÇ
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ package-lock.json
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ README.md
```

## ü©∫ Como funciona

Este job ser√° executado 1x por dia na **regi√£o** `us-central1`, com 2 CPUs, 8GB de mem√≥ria, sem retry e cria√ß√£o de apenas 1 task. Quando h√° atualiza√ß√£o de dados (uma vez por m√™s), o processo dura cerca de 3 horas. Nas outras execu√ß√µes, ele leva menos de 1 minuto, pois apenas verifica se precisa ser executado (isto √© feito pois n√£o sabemos o dia em que a receita prover√° a atualiza√ß√£o).

### 1. Scraping do reposit√≥rio da Receita Federal

Inicialmente, √© realizada uma chamada para o reposit√≥rio oficial da Receita Federal.

Em seguida, identificamos a √∫ltima vers√£o dos dados dispon√≠vel, pois a Receita gera todos os dados mensalmente e os organiza em diret√≥rios, como `2025-01`, representando janeiro de 2025.

Ap√≥s identificar o diret√≥rio mais atual, os nomes dos arquivos ZIP tamb√©m s√£o obtidos para posterior download.

### 2. Verifica√ß√£o do processamento mensal

Caso os dados do m√™s j√° tenham sido processados, o job encerra antes de realizar qualquer download.

Isso ocorre porque h√° um arquivo armazenado no bucket que registra a √∫ltima vers√£o de dados processados. Esse arquivo √© atualizado ap√≥s a √∫ltima etapa do job, evitando custos desnecess√°rios.

### 3. Download dos dados

Se os dados mais recentes ainda n√£o foram obtidos, o processo de download √© iniciado.

Caso o arquivo CSV correspondente ao ZIP n√£o esteja armazenado, conforme descrito em [storage](../storage/), o download come√ßa. √Ä medida que os dados s√£o recebidos, eles s√£o gravados diretamente para evitar sobrecarga de mem√≥ria.

### 4. Extra√ß√£o dos dados

Ap√≥s o download, o conte√∫do do ZIP √© extra√≠do linha a linha, validando o charset e gerando um arquivo CSV com o mesmo nome do ZIP.

### 5. Upload dos dados

Por fim, o CSV √© enviado para o bucket e o arquivo ZIP √© exclu√≠do.

> Durante todas as etapas, o job gera logs que s√£o enviadas para o [Google Cloud Logging](https://cloud.google.com/logging), al√©m de alertas para um canal no [Slack](https://slack.com).

## üíµ Custos

Considerando as condi√ß√µes de execu√ß√£o e a [tabela de pre√ßos](https://cloud.google.com/run/pricing) com o free tier, temos os seguintes custos:

| **Opera√ß√£o** | **Custo por unidade** | **Uso estimado** | **Custo final (USD)** |
|--------------|-----------------------|------------------|-----------------------|
| Tempo de CPU (execu√ß√£o completa) | $0.000024 por CPU-minuto | 360 CPU-minutos | $0.00864 |
| Tempo de Mem√≥ria (execu√ß√£o completa) | $0.0000025 por GB-minuto | 1,440 GB-minutos | $0.0036 |
| Solicita√ß√£o (execu√ß√£o completa) | $0.40 por 1M solicita√ß√µes | 1 solicita√ß√£o | $0.0000004 |
| Tempo de CPU (execu√ß√µes r√°pidas) | $0.000024 por CPU-minuto | 58 CPU-minutos | $0.001392 |
| Tempo de Mem√≥ria (execu√ß√µes r√°pidas) | $0.0000025 por GB-minuto | 232 GB-minutos | $0.00058 |
| Solicita√ß√µes (execu√ß√µes r√°pidas) | $0.40 por 1M solicita√ß√µes | 29 solicita√ß√µes | $0.0000116 |
| **Total mensal estimado** | **‚Äî** | **‚Äî** | **$0.01422** |
| **Total ap√≥s n√≠vel gratuito** | **‚Äî** | **‚Äî** | **$0.00** |

## üõ†Ô∏è Como realizar o deploy

Certifique-se de ter instalado o [Google Cloud SDK CLI](https://cloud.google.com/sdk/docs/install), [Docker](https://docs.docker.com/desktop/) e [NodeJS](https://nodejs.org). Sua conta de e-mail vinculada ao projeto do Google Cloud tamb√©m deve ter as permiss√µes necess√°rias.

Para realizar o deploy, execute o script [`deploy.sh`](./deploy.sh) e configure as vari√°veis no in√≠cio do arquivo.

Para executar o job no Google Cloud:
```sh
gcloud run jobs execute $JOB_NAME --region=$REGION
```

> Esta etapa tamb√©m pode ser realizada via [Google Console](https://console.cloud.google.com/run/jobs).

## ü™õ Como executar localmente

Crie um arquivo `.env` na raiz do projeto:
```env
PROCESS=cnpj-data-fetcher
GOOGLE_CLOUD_PROJECT=cloud-cnpj
GOOGLE_CLOUD_BUCKET=cloud-cnpj
RECEITA_FEDERAL_URL=https://arquivos.receitafederal.gov.br/dados/cnpj/dados_abertos_cnpj
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...
LOG_ENABLED=true
SLACK_NOTIFICATIONS_ENABLED=false
```

Instale as depend√™ncias e execute o job localmente:
```sh
npm install
npm start
```

> Se n√£o for usar notifica√ß√µes do Slack, n√£o √© necess√°rio configurar a URL. Para ativ√°-las, siga [estas instru√ß√µes](https://api.slack.com/messaging/webhooks).
