# Prepare

Esta etapa do processo √© respons√°vel pela prepara√ß√£o dos dados que foram previamente obtidos no processo [ingestion](../ingestion/). Sua responsabilidade √© importar os arquivos CSV presentes no [Google Cloud Storage](https://cloud.google.com/storage), tornando-os registros em tabelas do [Google BigQuery](https://cloud.google.com/bigquery).

## üèó Estrutura

```
‚îú‚îÄ‚îÄ gold/                       # Arquivos relacionados aos dados refinados
‚îÇ   ‚îú‚îÄ‚îÄ create.sql              # Query para criar datasets e tabelas
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh               # Script para criar transfers que refinam os dados
‚îÇ   ‚îú‚îÄ‚îÄ estabelecimentos.sql    # Query para refinar os dados de estabelecimentos
|
‚îú‚îÄ‚îÄ raw/                        # Arquivos relacionados aos dados brutos
‚îÇ   ‚îú‚îÄ‚îÄ create.sql              # Query para criar datasets e tabelas
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh               # Script para criar transfers que importam dados do storage para o BQ
|
‚îú‚îÄ‚îÄ deploy.sh                   # Script geral para criar datasets, tabelas e transfers
‚îú‚îÄ‚îÄ README.md
```

## ü©∫ Como funciona

### 1. Camada raw

O dataset `raw` foi criado no BigQuery, na **region** `us-central1`. Este dataset possui todas as tabelas conforme descri√ß√£o do [dicion√°rio de dados da Receita Federal](https://www.gov.br/receitafederal/dados/cnpj-metadados.pdf).

| Tabela | Dataset | Descri√ß√£o |
|--------|---------|-----------|
| `cnaes` | `raw` | Armazena os c√≥digos e descri√ß√µes das atividades econ√¥micas (CNAE) |
| `empresas` | `raw` | Cont√©m os dados cadastrais das empresas |
| `estabelecimentos` | `raw` | Registra os estabelecimentos vinculados √†s empresas |
| `motivos` | `raw` | Lista os c√≥digos e descri√ß√µes dos motivos de situa√ß√£o cadastral |
| `municipios` | `raw` | Cont√©m os c√≥digos e nomes dos munic√≠pios |
| `naturezas` | `raw` | Tabela de c√≥digos e descri√ß√µes das naturezas jur√≠dicas |
| `paises` | `raw` | Lista os c√≥digos e nomes dos pa√≠ses |
| `qualificacoes` | `raw` | Armazena os c√≥digos e descri√ß√µes das qualifica√ß√µes de s√≥cios |
| `simples` | `raw` | Indica a op√ß√£o da empresa pelo Simples Nacional e MEI |
| `socios` | `raw` | Cont√©m os dados dos s√≥cios das empresas |
| `portes` | `raw` | Cont√©m os dados dos portes das empresas |
| `situacoes` | `raw` | Cont√©m os dados das situa√ß√µes cadastrais das empresas |

Os dados dos arquivos CSV presentes no Storage s√£o importados para tabelas no BigQuery por meio de [Data Transfers](https://cloud.google.com/bigquery/docs/dts-introduction).

Os transfers foram configurados para serem executados sob demanda. Eles utilizam a op√ß√£o **MIRROR**, o que significa que os dados existentes ser√£o substitu√≠dos a cada execu√ß√£o.

Al√©m disso, ao final, o arquivo CSV √© exclu√≠do do Storage ap√≥s a importa√ß√£o para o BigQuery.

| Nome | GCS Path | Dataset | Tabela |
|------|----------|---------|--------|
| `cnaes-storage-bq` | `gs://cloud-cnpj/cnaes/*.csv` | `raw` | `cnaes` |
| `empresas-storage-bq` | `gs://cloud-cnpj/empresas/*.csv` | `raw` | `empresas` |
| `estabelecimentos-storage-bq` | `gs://cloud-cnpj/estabelecimentos/*.csv` | `raw` | `estabelecimentos` |
| `motivos-storage-bq` | `gs://cloud-cnpj/motivos/*.csv` | `raw` | `motivos` |
| `municipios-storage-bq` | `gs://cloud-cnpj/municipios/*.csv` | `raw` | `municipios` |
| `naturezas-storage-bq` | `gs://cloud-cnpj/naturezas/*.csv` | `raw` | `naturezas` |
| `paises-storage-bq` | `gs://cloud-cnpj/paises/*.csv` | `raw` | `paises` |
| `qualificacoes-storage-bq` | `gs://cloud-cnpj/qualificacoes/*.csv` | `raw` | `qualificacoes` |
| `simples-storage-bq` | `gs://cloud-cnpj/simples/*.csv` | `raw` | `simples` |
| `socios-storage-bq` | `gs://cloud-cnpj/socios/*.csv` | `raw` | `socios` |

> Este procedimento n√£o √© agendado pois √© controlado por um workflow.
> As entidades possuem o campo `data_criacao` que indica a data e hora de inser√ß√£o daquele registro em cada tabela.

### 2. Camada gold

O dataset `gold` foi criado na **region** `us-central1`. Este dataset possui todas as tabelas com dados tratados, ou seja, dados refinados que ser√£o √∫teis para o o consumo de usu√°rios.

Esses dados s√£o gerados por meio de execu√ß√µes de [query agendadas do BigQuery](https://cloud.google.com/bigquery/docs/scheduling-queries). Essas queries l√™m dados da camada `raw` e os disponibilizam em tabelas da camada `gold`.

| Tabela | Dataset | Descri√ß√£o |
|--------|---------|-----------|
| `estabelecimentos` | `gold` | Unifica e trata todos os dados de empresas, s√≥cios, estabelecimentos e demais entidades |

> Este procedimento n√£o √© agendado pois √© controlado por um workflow.
> A entidade possui o campo `data_criacao` que indica a data e hora de inser√ß√£o daquele registro na tabela.

## üíµ Custos

Considerando que todas as tabelas da camada `raw` utilizar√£o 20GB de armazenamento e a camada `gold` faz uso de 40GB, pelo fato de estar sendo utilizada a **region** `us-central1`, de acordo com a [tabela de custos](https://cloud.google.com/bigquery/pricing) e considerando o free tier, os valores seriam os seguintes:

| Opera√ß√£o | Custo por unidade | Uso estimado | Custo final (USD) |
|----------|-------------------|--------------|-------------------|
| Armazenamento (gold) | $0.02 por GB/m√™s | 40 GB | $0.80 |
| Armazenamento (raw) | $0.02 por GB/m√™s | 20 GB | $0.40 |
| Ingest√£o via Data Transfer (raw) | $0.00 (se origem for Google Cloud) | 60 GB | $0.00 |
| Processamento (ingest√£o na raw) | $5.00 por TB processado | 50 GB (0.05 TB) | $0.25 |
| Processamento (ingest√£o na gold) | $5.00 por TB processado | 50 GB (0.05 TB) | $0.25 |
| **Total mensal estimado** | **‚Äî** | **‚Äî** | **$1.70** |

## üõ†Ô∏è Como realizar o deploy

Antes de iniciar, certifique-se de possuir o [Google Cloud SDK CLI](https://cloud.google.com/sdk/docs/install) instalado em sua m√°quina. Al√©m disso, √© necess√°rio que sua conta de e-mail vinculada ao projeto do Google Cloud possua as permiss√µes necess√°rias.

Com tudo pronto, basta executar o script [`deploy.sh`](./deploy.sh), sempre lembrando de configurar as vari√°veis no in√≠cio do arquivo.

> Esta n√£o √© uma etapa obrigat√≥ria, podendo ser realizada por meio da UI do [Google Console](https://console.cloud.google.com/bigquery).

### Notifica√ß√µes por e-mail

Para receber alertas em caso de falha, √© necess√°rio configurar as notifica√ß√µes manualmente pelo Cloud Console:

1. Acesse o [BigQuery Data Transfer Service](https://console.cloud.google.com/bigquery/transfers).
2. Selecione a transfer√™ncia criada.
3. Clique em **"Editar configura√ß√£o"**.
4. Ative a op√ß√£o **"Enviar e-mails em caso de falha"**.
5. Salve as altera√ß√µes.

## ü™õ Como trigar localmente

Caso ainda n√£o tenha feito, certifique-se de possuir o [Google Cloud SDK CLI](https://cloud.google.com/sdk/docs/install) instalado em sua m√°quina. Al√©m disso, √© necess√°rio que sua conta de e-mail vinculada ao projeto do Google Cloud possua as permiss√µes necess√°rias.

```
bq mk --transfer_run \
    --project_id=$PROJECT \
    --location=$LOCATION \
    --run_time=$(date -u +"%Y-%m-%dT%H:%M:%SZ") \
    projects/$PROJECT_ID/locations/us/transferConfigs/$TRANSFER_ID
```
